{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition using Facenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOl8q/mOrAWrZ2LCWS5p2f7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prananto/baud.prananto/blob/main/Face_Recognition_using_Facenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and extract files:**\n",
        "\n",
        "facenet_keras.h5\n",
        "\n",
        "datakelas.zip"
      ],
      "metadata": {
        "id": "4t1SEWfbzGq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1kv4Q5T0dNjWSVWcV6_IU9zXq4-5eszh9\n",
        "!gdown --id 1jt1BltL_8PSDLtT00VwkO57YsR23IE9b\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/datakelas.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4RTnRpWayWP",
        "outputId": "52aef0c0-cf46-4558-e11a-62e96f9a5a08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kv4Q5T0dNjWSVWcV6_IU9zXq4-5eszh9\n",
            "To: /content/facenet_keras.h5\n",
            "100% 92.4M/92.4M [00:01<00:00, 55.6MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jt1BltL_8PSDLtT00VwkO57YsR23IE9b\n",
            "To: /content/datakelas.zip\n",
            "100% 28.9M/28.9M [00:00<00:00, 36.2MB/s]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKOTo3k0Y8cC",
        "outputId": "362117ae-20ad-45a4-99c1-783569003440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.5)\n",
            ">loaded 1 examples for class: m_khaerul_naim\n",
            ">loaded 1 examples for class: arief_ichwani\n",
            ">loaded 2 examples for class: dewi_tresnawati\n",
            ">loaded 5 examples for class: handoko_supeno\n",
            ">loaded 2 examples for class: ahmad_luky_ramdani\n",
            ">loaded 1 examples for class: varuliantor_dear\n",
            ">loaded 1 examples for class: leni_fitriani\n",
            ">loaded 2 examples for class: imam_ekowicaksono\n",
            ">loaded 1 examples for class: sulthoni_ashiddiiqi\n",
            ">loaded 1 examples for class: ricky_isfandiari\n",
            ">loaded 2 examples for class: mina_ismu_rahayu\n",
            ">loaded 2 examples for class: baud_prananto\n",
            ">loaded 1 examples for class: kemas_muhammad_irsan_riza\n",
            ">loaded 4 examples for class: rahman_indra_kesuma\n",
            ">loaded 1 examples for class: yulrio_brianorman\n",
            ">loaded 1 examples for class: achmad_indra_aulia\n",
            ">loaded 2 examples for class: hartanto_tantriawan\n",
            ">loaded 2 examples for class: reza_budiawan\n",
            ">loaded 2 examples for class: arief_sartono\n",
            ">loaded 3 examples for class: lathifah_arief\n",
            ">loaded 2 examples for class: meredita_susanty\n",
            ">loaded 1 examples for class: adiyasa_nurfalah\n",
            ">loaded 3 examples for class: meza_silvana\n",
            "(43, 160, 160, 3) (43,)\n",
            ">loaded 1 examples for class: ahmad_luky_ramdani\n",
            ">loaded 1 examples for class: imam_ekowicaksono\n",
            ">loaded 11 examples for class: unknown\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn\n",
        "# face detection for the 5 Celebrity Faces Dataset\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# enumerate files\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + filename\n",
        "\t\t# get face\n",
        "\t\tface = extract_face(path)\n",
        "\t\t# store\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces\n",
        "\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# enumerate folders, on per class\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# skip any files that might be in the dir\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# load all faces in the subdirectory\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# create labels\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\t# store\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)\n",
        "\n",
        "# load train dataset\n",
        "trainX, trainy = load_dataset('/content/datakelas/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "testX, testy = load_dataset('/content/datakelas/val/')\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('kelas-dataset.npz', trainX, trainy, testX, testy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate a face embedding for each face in the dataset using facenet\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "\n",
        "# get the face embedding for one face\n",
        "def get_embedding(model, face_pixels):\n",
        "\t# scale pixel values\n",
        "\tface_pixels = face_pixels.astype('float32')\n",
        "\t# standardize pixel values across channels (global)\n",
        "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
        "\tface_pixels = (face_pixels - mean) / std\n",
        "\t# transform face into one sample\n",
        "\tsamples = expand_dims(face_pixels, axis=0)\n",
        "\t# make prediction to get embedding\n",
        "\tyhat = model.predict(samples)\n",
        "\treturn yhat[0]\n",
        "\n",
        "# load the face dataset\n",
        "data = load('kelas-dataset.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "# load the facenet model\n",
        "model = load_model('facenet_keras.h5')\n",
        "print('Loaded Model')\n",
        "# convert each face in the train set to an embedding\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# convert each face in the test set to an embedding\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnewTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('kelas-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ],
      "metadata": {
        "id": "SYBPeSr9dHh8",
        "outputId": "ed66194f-aada-4f7a-c4dc-129ded13afb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded:  (43, 160, 160, 3) (43,) (13, 160, 160, 3) (13,)\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Loaded Model\n",
            "(43, 128)\n",
            "(13, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# develop a classifier for the Dataset\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "# load faces\n",
        "data = load('kelas-dataset.npz')\n",
        "testX_faces = data['arr_2']\n",
        "# load face embeddings\n",
        "data = load('kelas-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# test model on a random example from the test dataset\n",
        "selection = choice([i for i in range(testX.shape[0])])\n",
        "random_face_pixels = testX_faces[selection]\n",
        "random_face_emb = testX[selection]\n",
        "random_face_class = testy[selection]\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
        "# prediction for the face\n",
        "samples = expand_dims(random_face_emb, axis=0)\n",
        "yhat_class = model.predict(samples)\n",
        "yhat_prob = model.predict_proba(samples)\n",
        "# get name\n",
        "class_index = yhat_class[0]\n",
        "class_probability = yhat_prob[0,class_index] * 100\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
        "print('Expected: %s' % random_face_name[0])\n",
        "# plot for fun\n",
        "pyplot.imshow(random_face_pixels)\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "pyplot.title(title)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "-55_HEzelrYM",
        "outputId": "5f83875d-523b-4909-cd08-3c388dab6c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'unknown'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3289cee073c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mout_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrainy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtesty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'unknown'"
          ]
        }
      ]
    }
  ]
}